{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJECT: Course Optimization for Data Science\n",
    "## Optimization strategies for Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors: Alexandre Gramfort, Stéphane Gaiffas\n",
    "\n",
    "If you have questions or if something is not clear in the text below please contact us\n",
    "by email.\n",
    "\n",
    "## Aim:\n",
    "\n",
    "- derive the duals for SVMs with and without intercept\n",
    "- implement an SVM using a blackbox convex toolbox (cvxopt in Python)\n",
    "- implement your own solvers for the without intercept case: Proximal gradient, Coordinate Descent, Newton, Quasi-Newton\n",
    "- Present a clear benchmark of the different strategies on small and medium scale datasets\n",
    "\n",
    "\n",
    "## VERY IMPORTANT\n",
    "\n",
    "This work must be done by pairs of students.\n",
    "Each student must send their work before the 3rd of January at 23:59, using the moodle platform.\n",
    "This means that **each student in the pair sends the same file**\n",
    "\n",
    "On the moodle, in the \"Optimization for Data Science\" course, you have a \"devoir\" section called \"Project\".\n",
    "This is where you submit your jupyter notebook file.\n",
    "\n",
    "The name of the file must be constructed as in the next cell\n",
    "\n",
    "### Gentle reminder: no evaluation if you don't respect this EXACTLY\n",
    "\n",
    "#### How to construct the name of your file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_martigny_peter_and_choffin_benoît.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Change here using YOUR first and last names\n",
    "fn1 = \"peter\"\n",
    "ln1 = \"martigny\"\n",
    "fn2 = \"benoît\"\n",
    "ln2 = \"choffin\"\n",
    "\n",
    "filename = \"_\".join(map(lambda s: s.strip().lower(), \n",
    "                        [\"project\", ln1, fn1, \"and\", ln2, fn2])) + \".ipynb\"\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important:\n",
    "\n",
    "For Part 0 to Part 2 of the project you will need a working install of `cvxopt`.\n",
    "You may struggle a bit to set it up.\n",
    "The simplest way of getting it is by typing \n",
    "\n",
    "`pip install cvxopt`\n",
    "\n",
    "if you have `pip` installed on your laptop.\n",
    "If you **struggle too much please\n",
    "contact us**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: SVM Classification with linear kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider the problem of binary classification from $n$ observations\n",
    "$x_i \\in \\mathbb{R}^{d}$,\n",
    "$1 \\leq i \\leq n$. We aim to learn a function:\n",
    "$$f: x \\in \\mathbb{R}^{d}\\mapsto y\\in\\{-1,+1\\}$$\n",
    "from the $n$ annotated training samples $(x_{i},y_{i})$ supposed i.i.d. from an unknown probability distribution on $\\mathbb{R}^d \\times \\{-1,+1\\}$. Once this function is learnt, it will be possible to use it to predict the label $y$ associated to a new sample $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Margin and linear separating hyperplane:\n",
    "\n",
    "<img src=\"separateur.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the linear case, one looks for an affine function of $x$ of the form \n",
    "$f(x) = \\mathrm{sign}(w^{\\top} x)$ or $f(x)=\\mathrm{sign}(w^{\\top}x + b)$\n",
    "with $w \\in \\mathbb{R}^d$ and $b \\in \\mathbb{R}$. The first case is referred\n",
    "to as the **without intercept** case. Indeed the coefficient $b$ is known\n",
    "as the intercept or bias term.\n",
    "\n",
    "We will start by considering the case with intercept.\n",
    "\n",
    "To learn $f$, we use the $n$ annotated samples and one looks for a hyperplane $P(w,b)$\n",
    "such that the smallest distance to positive and negative samples\n",
    "is the largest. This can be written as:\n",
    "$$\n",
    " \\max_{w,b} \\min_{i=1:n} d(x_{i},P(w,b)) \\quad\n",
    " \\text{where}\\quad d(x_{i},P(w,b)) = \\frac{|w^{\\top}x_{i}+b|}{\\sqrt{w^{\\top}w}} \\enspace,\n",
    "$$\n",
    "since the signed distance from a sample $x_{i}$ to the hyperplane $P(w,b)$ is given by\n",
    "$$\n",
    " \\delta(x_{i},w,b) = \\frac{w^{\\top}x_{i}+b}{\\sqrt{w^{\\top}w}}.\n",
    "$$\n",
    "The principle described above is the maximisation of the *margin*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can notice that if the minimum of a set of values is larger than $m$ then all values of the set are larger than $m$. This leads to the following problem formulation:\n",
    "$$\n",
    " \\left\\{\n",
    " \\begin{array}{cll}\n",
    " \\max_{(w,b)} \\quad m \\\\\n",
    " \\text{s.t.} \\;\\; &\\forall i &\\dfrac{|w^{\\top}x_{i}+b|}{\\sqrt{w^{\\top}w}}\\geq m\n",
    " \\end{array}\n",
    " \\right. \\enspace .\n",
    "$$\n",
    "\n",
    "The hyperplane separates the space in 2 half spaces, depending if $\\delta(x_{i},w,b)$ is positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming all samples are linearly separable, convince yourself that the problem can be written as:\n",
    "$$\n",
    "(\\mathcal{P}):  \\left\\{\n",
    " \\begin{array}{cll}\n",
    " &\\min_{(w,b)} \\frac{1}{2}w^{\\top}w\n",
    " \\\\\n",
    "  &y_{i}(w^{\\top}x_{i}+b)\\geq 1, \\quad \\forall i\\in \\{1,\\cdots,n\\}\n",
    " \\end{array}\n",
    " \\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q1: Justify that the problem $(\\mathcal{P})$ is convex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q2: By looking at the saddle points of the Lagrangian $\\mathcal{L}(w, b, \\mu)$, $\\mu \\in \\mathbb{R}_+^n$, show that the dual problem $(\\mathcal{D})$ can be written as:\n",
    "$$\n",
    "(\\mathcal{D}): \n",
    " \\left\\{\n",
    " \\begin{array}{lll}\n",
    " \\min_{\\mu} &\\frac{1}{2}\\mu^{\\top}GG^{t}\\mu-\\mu^{\\top}u\n",
    " \\\\\n",
    " \\mathrm{s.c.}& y^{\\top}\\mu = 0\n",
    " \\\\\n",
    " \\mathrm{and}& -\\mu \\leq  0\n",
    " \\end{array}\n",
    " \\right .\n",
    "$$\n",
    "\n",
    "with\n",
    "\n",
    "$$\n",
    " G = \\begin{bmatrix}y_{1}x_{1}^{\\top} \\\\ \\vdots \\\\ y_{n}x_{n}^{\\top}\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "and $u = (1, \\dots, 1) \\in \\mathbb{R}^n$.\n",
    "\n",
    "We will **assume here qualification of the contraints**.\n",
    "\n",
    "Remark: The problem $(\\mathcal{D})$ is a *quadratic program* (QP) for which their exist off-the-shelf techniques. See below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q3: Justify that given the estimated $\\mu$, the prediction function for a new sample $x$ is given by:\n",
    "\n",
    "$$\n",
    "y = \\mathrm{sign}(\\sum_{i=1}^{n} \\mu_i y_i x_i^\\top x + b) \\enspace .\n",
    "$$\n",
    "\n",
    "The vector $w$ is therefore equal to $\\sum_{i=1}^{n} \\mu_i y_i x_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Implementation of solver with intercept using cvxopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file svm_project_utils.py contains the code to generate some toy data and plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from svm_project_utils import plot_dataset, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAFkCAYAAAC9wjgoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQggZOf8fGvkWJjtYPiEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17260415dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = datasets(name='gaussian', n_points=300)\n",
    "plot_dataset(X, y)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The following function qp allows to solve a quadratic problem of the form:\n",
    "\n",
    "$$\n",
    "\\left\\{\n",
    "  \\begin{array}{cll}\n",
    "  &\\min_{(x)} \\frac{1}{2}x^{\\top} H x - e^\\top x\n",
    "  \\\\\n",
    "   & \\textrm{s.c.}\\; A^\\top x = b, 0 \\leq x \\leq C.\n",
    "  \\end{array}\n",
    "  \\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a08666465d6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[1;32mimport\u001b[0m \u001b[0mcvxopt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mqp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[1;31m# Gram matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Peter martigny\\Anaconda3\\lib\\site-packages\\cvxopt\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[1;32mimport\u001b[0m \u001b[0mcvxopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: DLL load failed: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "import cvxopt\n",
    "\n",
    "\n",
    "def qp(H, e, A, b, C=np.inf, l=1e-8, verbose=True):\n",
    "    # Gram matrix\n",
    "    n = H.shape[0]\n",
    "    H = cvxopt.matrix(H)\n",
    "    A = cvxopt.matrix(y, (1, n))\n",
    "    e = cvxopt.matrix(-e)\n",
    "    b = cvxopt.matrix(0.0)\n",
    "    if C == np.inf:\n",
    "        G = cvxopt.matrix(np.diag(np.ones(n) * -1))\n",
    "        h = cvxopt.matrix(np.zeros(n))\n",
    "    else:\n",
    "        G = cvxopt.matrix(np.concatenate([np.diag(np.ones(n) * -1),\n",
    "                                         np.diag(np.ones(n))], axis=0))\n",
    "        h = cvxopt.matrix(np.concatenate([np.zeros(n), C * np.ones(n)]))\n",
    "\n",
    "    # Solve QP problem\n",
    "    cvxopt.solvers.options['show_progress'] = verbose\n",
    "    solution = cvxopt.solvers.qp(H, e, G, h, A, b)\n",
    " \n",
    "    # Lagrange multipliers\n",
    "    mu = np.ravel(solution['x'])\n",
    "    return mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the linear kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kernel(X1, X2):\n",
    "    n1 = X1.shape[0]\n",
    "    n2 = X2.shape[0]\n",
    "    K = np.empty((n1, n2))\n",
    "    for i in range(n1):\n",
    "        for j in range(n2):\n",
    "            K[i, j] = np.dot(X1[i], X2[j])\n",
    "    return K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "- Q4: Modify the following cell to solve the SVM dual problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = datasets(name='gaussian', n_points=300, sigma=0.7)\n",
    "plot_dataset(X, y)\n",
    "\n",
    "# TODO\n",
    "def svm_solver(K, y, C=np.inf):\n",
    "    H = None\n",
    "    e = None\n",
    "    A = None\n",
    "    b = None\n",
    "    mu = qp(H, e, A, b, C, l=1e-8, verbose=False)\n",
    "    idx_support = np.where(np.abs(mu) > 1e-5)[0]\n",
    "    mu_support = mu[idx_support]\n",
    "    return mu_support, idx_support\n",
    "\n",
    "K = kernel(X, X)\n",
    "\n",
    "# Uncomment the following lines when your svm_solver is completed:\n",
    "# mu_support, idx_support = svm_solver(K, y)\n",
    "# print(\"Number of support vectors: %s\" % idx_support.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 10), (10,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.zeros(10)\n",
    "x.reshape((1, -1)).shape, x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q5: Compute w from mu and b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "w = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q6: Using complementary slackness, explain how to obtain $b$ from $\\mu$.\n",
    "\n",
    "HINT: Use the fact that for all support vectors for which $\\mu_i$ is non-zero one has $y_{i}(w^{t}x_{i}+b) = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "def compute_b(K, y, mu_support, idx_support):\n",
    "    # TODO\n",
    "    y_support = y[idx_support]\n",
    "    K_support = K[idx_support][:, idx_support]\n",
    "    b = None\n",
    "    return b\n",
    "\n",
    "b = compute_b(K, y, mu_support, idx_support)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q7: Verify that the constraints of the primal problem are satistified up to an acceptable numerical precision. You should verify that for all $i$ we have:\n",
    "\n",
    "$$\n",
    "y_{i}(w^{\\top}x_{i}+b) \\geq 1 - \\epsilon\n",
    "$$\n",
    "\n",
    "using for example $\\epsilon = 1e-5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your code by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = datasets(name='gaussian', n_points=300, sigma=0.7)\n",
    "\n",
    "K = kernel(X, X)\n",
    "mu_support, idx_support = svm_solver(K, y)\n",
    "b = compute_b(K, y, mu_support, idx_support)\n",
    "\n",
    "def plot_classif(X, y, mu_support, idx_support, b, kernel=kernel):\n",
    "    # Calcul de la fonction de décision sur une grille\n",
    "    X1, X2 = np.mgrid[-4:4:0.1, -4:4:0.1]\n",
    "    na, nb = X1.shape\n",
    "    X_test = np.c_[np.reshape(X1, (na * nb, 1)),\n",
    "                   np.reshape(X2, (na * nb, 1))]\n",
    "\n",
    "    # Calcul des produits scalaires\n",
    "    X_support = X[idx_support]\n",
    "    G = kernel(X_test, X_support)\n",
    "    # Calcul de la fonction de décision\n",
    "    decision = G.dot(mu_support * y[idx_support]) + b\n",
    "\n",
    "    # Calcul du label prédit\n",
    "    y_pred = np.sign(decision)\n",
    "\n",
    "    # Affichage des lignes de niveau de la fonction de decision\n",
    "    plt.contourf(X1, X2, np.reshape(decision, (na, nb)), 20, cmap=plt.cm.gray)\n",
    "    cs = plt.contour(X1, X2, np.reshape(decision, (na,nb)), [-1, 0, 1], color='g', linewidth=2)\n",
    "    plt.clabel(cs, inline=1)\n",
    "    plt.plot(X[y == 1,0], X[y == 1, 1], 'or', linewidth=2)\n",
    "    plt.plot(X[y == -1,0], X[y == -1, 1], 'ob', linewidth=2)\n",
    "    plt.xlabel('x1')\n",
    "    plt.ylabel('x2')\n",
    "    plt.xlim([-4, 4])\n",
    "    plt.ylim([-4, 4])\n",
    "\n",
    "plot_classif(X, y, mu_support, idx_support, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now change the value of $\\sigma$ such that the problem is not linearily separable anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = datasets(name='gaussian', n_points=300, sigma=1.5)\n",
    "plot_dataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K = kernel(X, X)\n",
    "mu_support, idx_support = svm_solver(K, y)\n",
    "b = compute_b(K, y, mu_support, idx_support)\n",
    "w = np.sum((mu_support * y[idx_support])[: , None] * X[idx_support], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q8: Check that contraints of the problem are now violated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Non separable case with cvxopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice it is very likely that the classes are not linearly separable.\n",
    "\n",
    "A very natural idea is to relax the constraints $y_{i}(w^\\top x_i + c) \\geq 1$.\n",
    "To do this, so called soft-margin SVM have been introduced using\n",
    "so called slack variables: $\\xi_{i}\\geq 0$. The problem becomes:\n",
    "\n",
    "$$\n",
    " y_{i}(w^\\top x_i + b) \\geq 1 - \\xi_i, \\; \\xi_i \\geq 0 \\enspace .\n",
    "$$\n",
    "\n",
    "Note that if $\\xi_i > 1$, the sample $x_{i}$ will be misclassified. To prevent\n",
    "this case to be too frequent, an idea is to minimize the sum of the $\\xi_{i}$.\n",
    "This leads to the following problem:\n",
    "\n",
    "$$\n",
    "(P_{s}):  \\left\\{\n",
    " \\begin{array}{ll}\n",
    " \\min_{(w,b,\\xi)} & \\frac{1}{2}w^{\\top}w + C \\sum_i \\xi_i\n",
    " \\\\\n",
    " \\mathrm{s.t.} & y_{i}(w^{\\top}x_{i}+b) \\geq 1 - \\xi_i\\\\\n",
    " \\mathrm{and} & -\\xi_i \\leq 0\n",
    " \\end{array}\n",
    " \\right.\n",
    "$$\n",
    "\n",
    "The constant $C$ controls the regularisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q9: Justify that $(P_{s})$ is a convex problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Show that a dual problem of $(P_{s})$ reads:\n",
    "\n",
    "$$\n",
    "(\\mathcal{D}):\n",
    "\\left\\{\n",
    "\\begin{array}{lll}\n",
    "\\min_{\\mu} &\\frac{1}{2}\\mu^{\\top}GG^{\\top}\\mu-\\mu^{\\top}u\n",
    "\\\\\n",
    "\\mathrm{s.t.}& y^{\\top}\\mu = 0\n",
    "\\\\\n",
    "\\mathrm{et}& 0 \\leq \\mu \\leq C\n",
    "\\end{array}\n",
    "\\right .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q10: Modify your code from Q4 to handle the non-separable case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "X, y = datasets(name='gaussian', n_points=300, sigma=1.7)\n",
    "\n",
    "K = kernel(X, X)\n",
    "# mu_support, idx_support = svm_solver(...)\n",
    "# b = compute_b(K, y, mu_support, idx_support)\n",
    "\n",
    "# plot_classif(X, y, mu_support, idx_support, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q11: What is the influence of C on the number of support vectors? Justify this from an optimization stand point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: non-linear case with kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another scenario is when the boundary between classes is not linear.\n",
    "\n",
    "To cope with this the idea is to use kernels.\n",
    "\n",
    "- Q12: Denoting by $K(x_i, x_j)$ the dot product between samples show that dual problem and the decision function f(x) can be reformulated just using calls to $K$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the clowns dataset to evaluate this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = datasets(name='clowns', n_points=200, sigma=0.7)\n",
    "\n",
    "plot_dataset(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q13: Update your kernel function so it computes the Gaussian kernel:\n",
    "\n",
    "$$\n",
    "    K(x_i, x_j) = \\exp(-\\gamma \\| x_i - x_j \\|)\n",
    "$$\n",
    "\n",
    "where $\\gamma > 0$ is the kernel bandwidth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "from scipy import linalg\n",
    "\n",
    "def rbf_kernel(X1, X2):\n",
    "    n1 = X1.shape[0]\n",
    "    n2 = X2.shape[0]\n",
    "    K = np.empty((n1, n2))\n",
    "    gamma = 3.\n",
    "    for i in range(n1):\n",
    "        for j in range(n2):\n",
    "            K[i, j] = 0  # CHANGE THIS\n",
    "    return K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the change above the follwing code should allow you to nicely separate the red from the blue dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = datasets(name='clowns', n_points=200, sigma=0.7)\n",
    "\n",
    "K = rbf_kernel(X, X)\n",
    "mu_support, idx_support = svm_solver(K, y, C=1.)\n",
    "b = compute_b(K, y, mu_support, idx_support)\n",
    "\n",
    "plot_classif(X, y, mu_support, idx_support, b, kernel=rbf_kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Linear SVM without intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem of the formuation of SVMs with the intercept term $b$ is that\n",
    "it leads to an annoying constraint in the dual, namely the $y^{t}\\mu = 0$.\n",
    "\n",
    "We will now see what we can do about it.\n",
    "\n",
    "Let's consider the problem\n",
    "\n",
    "$$\n",
    "(P'_{s}):  \\left\\{\n",
    " \\begin{array}{ll}\n",
    " \\min_{(w,\\xi)} & \\frac{1}{2}w^{\\top}w + C \\sum_i \\xi_i\n",
    " \\\\\n",
    " \\mathrm{s.t.} & y_{i}(w^{\\top}x_{i}) \\geq 1 - \\xi_i\\\\\n",
    " \\mathrm{and} & -\\xi_i \\leq 0\n",
    " \\end{array}\n",
    " \\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q14: Show that a dual problem of $(P'_{s})$ is given by:\n",
    "\n",
    "$$\n",
    "(\\mathcal{D}):\n",
    "\\left\\{\n",
    "\\begin{array}{lll}\n",
    "\\min_{\\mu} &\\frac{1}{2}\\mu^{\\top}GG^{\\top}\\mu-\\mu^{\\top} 1_n\n",
    "\\\\\n",
    "\\mathrm{s.t.}& 0 \\leq \\mu \\leq C\n",
    "\\end{array}\n",
    "\\right .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q15: Rewrite the dual in the form:\n",
    "\n",
    "\n",
    "$$\n",
    "(\\mathcal{D}): \\min_{\\mu} f(\\mu) + g(\\mu) .\n",
    "$$\n",
    "\n",
    "where $f$ is here a smooth function of $\\mu$ with L-Liptschitz gradient and $g$ is a non-smooth function that is separable, namely:\n",
    "\n",
    "$$\n",
    "g(\\mu) = \\sum_{i=1}^n g_i(\\mu_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dual in the later form can be readily optimized using the methods that you have been studying in this class:\n",
    "\n",
    "- Proximal gradient method with and without acceleration\n",
    "- L-BFGS-B\n",
    "- Coordinate descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q16: Implement:\n",
    "\n",
    "   - your own version of proximal gradient with and without acceleration\n",
    "   - your own version of coordinate descent\n",
    "   - an L-BFGS-B solver using `scipy.optimize.fmin_l_bfgs_b`\n",
    "\n",
    "Note: We restrict ourselves to linear kernel here.\n",
    "\n",
    "Note: To handle separating hyperplanes which do not pass throw zero (due to abscence of intercept)\n",
    "you will add a column of ones to X. You can use something like this:\n",
    "\n",
    "`X = np.concatenate((X, np.ones((len(X), 1))), axis=1)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will test your implementations on the Gaussian blobs and evaluate the performance of your implementations in terms of computation time on problems where the matrix $G G^\\top$ can fit in memory.\n",
    "\n",
    "You should reuse as much as possible the convergence evaluation code that you used during the labs.\n",
    "\n",
    "For a coordinate descent method to be fast you need to have smart updates. You're expected to\n",
    "come up with these smart updates in the problem at hand.\n",
    "\n",
    "BONUS : With a smart implementation of the coordinate descent you should be able to scale the optimization to tens of thousands of samples ie cases where $G G^\\top$ does not fit in memory anymore.\n",
    "\n",
    "**IMPORTANT : This question Q16 is the most important and will constitute half of the final grade on the project !**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "from scipy.optimize import fmin_l_bfgs_b"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
